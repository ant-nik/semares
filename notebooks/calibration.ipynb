{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0",
      "metadata": {
        "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0"
      },
      "source": [
        "# Camera calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6468cf32-7430-49eb-8576-1f798ef0c846",
      "metadata": {
        "id": "6468cf32-7430-49eb-8576-1f798ef0c846"
      },
      "source": [
        "Notebook is based on OpenCV tutorial (https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)\n",
        "\n",
        "\n",
        "see also for visualization:\n",
        "\n",
        "https://www.rerun.io/\n",
        "\n",
        "\n",
        "online viewer:\n",
        "\n",
        "https://www.rerun.io/viewer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0",
      "metadata": {
        "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0"
      },
      "outputs": [],
      "source": [
        "!wget -O samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/position.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import logging\n",
        "import io\n",
        "import numpy\n",
        "import plotly.express as plte\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "# termination criteria\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "\n",
        "def load_image(payload: any) -> any:\n",
        "    np_image = numpy.frombuffer(payload, numpy.uint8)\n",
        "    img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_chess_corners_from_image(\n",
        "        image: any, corners_x: int, corners_y: int) -> tuple[any, any]:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find the chess board corners\n",
        "    ret, corners = cv2.findChessboardCorners(gray, (corners_x, corners_y), None)\n",
        "\n",
        "    # If found, add object points, image points (after refining them)\n",
        "    if ret != True:\n",
        "        logger.error(\"Error, grid (%d, %d) is not found in image\",\n",
        "                     corners_x, corners_y)\n",
        "        return None, gray\n",
        "\n",
        "    corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1,-1), criteria)\n",
        "    result_image = cv2.drawChessboardCorners(image, (7,7), corners, True)\n",
        "    return corners2, result_image\n",
        "\n",
        "\n",
        "def undistort_image(image: numpy.ndarray, mtx: numpy.ndarray,\n",
        "                    dist: numpy.ndarray, new_mtx: numpy.ndarray,\n",
        "                    canvas_w: int, canvas_h: int) -> numpy.ndarray:\n",
        "    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, new_mtx,\n",
        "                                             (canvas_w, canvas_h), 5)\n",
        "    return cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n"
      ],
      "metadata": {
        "id": "8cpIb1CoYF0Q"
      },
      "id": "8cpIb1CoYF0Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import logging\n",
        "import functools\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_single_image(item: pandas.Series, url_template: str) -> numpy.ndarray:\n",
        "    item_file = item[\"image\"].lstrip(\" \")\n",
        "    url = url_template.format(item_file)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        logger.error(\"Can't read image %s from url %s\", item_file, url)\n",
        "    return pandas.Series([load_image(response.content), url],\n",
        "                         index=[\"image_data\", \"url\"])\n",
        "\n",
        "\n",
        "def load_images_and_meta(filename: str, base_url: str) -> pandas.DataFrame:\n",
        "    dataframe = pandas.read_csv(filename, sep=',')\n",
        "    orig_files = []\n",
        "    for index, item in dataframe.iterrows():\n",
        "        item_file = item[\"image\"].lstrip(\" \")\n",
        "        url = base_url.format(item_file)\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            logger.error(\"Can't read image %s from url %s\", item_file, url)\n",
        "        # Draw and display the corners\n",
        "        orig_image = load_image(response.content)\n",
        "        orig_files.append({\n",
        "            \"orig_image\": numpy.array(orig_image),\n",
        "            \"url\": url\n",
        "        })\n",
        "    dataframe.assign(orig_image=orig_files)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "dkjeAK9S7l-H"
      },
      "id": "dkjeAK9S7l-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def match_points(\n",
        "        corners_x: numpy.ndarray,\n",
        "        corners_y: numpy.ndarray,\n",
        "        corners: numpy.ndarray,\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray]:\n",
        "    objp = numpy.zeros((corners_x*corners_y, 3), numpy.float32)\n",
        "    objp[:,:2] = numpy.mgrid[0:corners_x, 0:corners_y].T.reshape(-1, 2)\n",
        "    return objp\n",
        "\n",
        "\n",
        "def calculate_image_corners(\n",
        "        row: pandas.Series, ignore_list: str, shapes: numpy.ndarray\n",
        ") -> pandas.Series:\n",
        "    if row[\"image\"] in ignore_list:\n",
        "        return pandas.Series(\n",
        "            [\n",
        "                None,\n",
        "                None\n",
        "            ], index=[\"corners\", \"chess_image\"]\n",
        "        )\n",
        "    corners, image = get_chess_corners_from_image(\n",
        "        image=row[\"image_data\"],\n",
        "        corners_x=row[\"corners_x\"],\n",
        "        corners_y=row[\"corners_y\"]\n",
        "    )\n",
        "\n",
        "    img_shape = (row[\"image_data\"].shape[1], row[\"image_data\"].shape[0])\n",
        "    #if shapes != img_shape:\n",
        "    #    logger.error(\n",
        "    #        \"Image %s has specific shape %s that is not equals to previously shapes: %s\",\n",
        "    #        sample.name, str(img_shape), str(shapes)\n",
        "    #        )\n",
        "    #    return pandas.Series([None, None, None], index=[\"obj_points\", \"image_points\"])\n",
        "\n",
        "    if corners is None:\n",
        "        objp = None\n",
        "        logger.error(\"Can't find %d, %d conrenrs in %s\",\n",
        "                     row[\"corners_x\"], row[\"corners_y\"], row[\"image\"])\n",
        "    else:\n",
        "        objp = match_points(corners_x=row[\"corners_x\"],\n",
        "                            corners_y=row[\"corners_y\"],\n",
        "                            corners=corners)\n",
        "\n",
        "    return pandas.Series([\n",
        "        corners,\n",
        "        image,\n",
        "        objp\n",
        "    ], index=[\"corners\", \"chess_image\", \"object_points\"])\n"
      ],
      "metadata": {
        "id": "HvPyuScqRUrK"
      },
      "id": "HvPyuScqRUrK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/{}\"\n",
        "ignore_list = [\n",
        "    \"image75_r.jpg\", \"image84_r.jpg\",\n",
        "    \"image84_l.jpg\", \"image89_r.jpg\",\n",
        "    \"image89_l.jpg\", \"image91_r.jpg\",\n",
        "    \"image91_l.jpg\"]\n",
        "\n",
        "dataframe = pandas.read_csv(\"samples.csv\", sep=',')\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            load_single_image,\n",
        "            url_template=base_url),\n",
        "        axis=1)\n",
        ")\n",
        "shapes = dataframe[\"image_data\"].apply(lambda x: x.shape).unique()\n",
        "if shapes.shape[0] != 1:\n",
        "    logger.error(\"More than one unique image sizes were found: %s\",\n",
        "                 str(shapes))\n",
        "shapes = (shapes[0][1], shapes[0][0])\n",
        "shapes"
      ],
      "metadata": {
        "id": "UqzgtBZZDTps"
      },
      "id": "UqzgtBZZDTps",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            calculate_image_corners,\n",
        "            ignore_list=ignore_list,\n",
        "            shapes=None),\n",
        "        axis=1)\n",
        ")\n",
        "dataframe.columns"
      ],
      "metadata": {
        "id": "6S7JcrjVjD2t"
      },
      "id": "6S7JcrjVjD2t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered = dataframe[~dataframe[\"image\"].isin(ignore_list)]\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "    filtered[\"object_points\"].tolist(),\n",
        "    filtered[\"corners\"].tolist(), shapes,\n",
        "    None, None)\n",
        "filtered = filtered.assign(rvecs=rvecs, tvecs=tvecs)\n",
        "filtered.columns"
      ],
      "metadata": {
        "id": "t4wx2mO7gn8J"
      },
      "id": "t4wx2mO7gn8J",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = shapes[0]\n",
        "h = shapes[1]\n",
        "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
        "(roi, newcameramtx)"
      ],
      "metadata": {
        "id": "BE2M-lqMlpjw"
      },
      "id": "BE2M-lqMlpjw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def draw_chess_images(row: pandas.Series):\n",
        "    names = []\n",
        "    error_threshold = 0.15\n",
        "    axis = numpy.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
        "    color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "    undistorted_images = []\n",
        "\n",
        "    if sample.corners is None:\n",
        "        fig = plte.imshow(sample.image, title=sample.name)\n",
        "        fig.show()\n",
        "        logger.warning(\"Image %s has no detected chessboard corners, skipping...\",\n",
        "                       sample.name)\n",
        "        return\n",
        "    pre_dst = undistort_image(\n",
        "        image=sample.image,\n",
        "        mtx=mtx, dist=dist, new_mtx=newcameramtx,\n",
        "        canvas_w=shapes[0], canvas_h=shapes[1])\n",
        "    # crop the image\n",
        "    x, y, w, h = roi\n",
        "    dst = pre_dst # [y:y + h, x:x + w]\n",
        "    imgpoints, _ = cv2.projectPoints(\n",
        "        sample.obj_points, sample.rvec, sample.tvec, mtx, dist)\n",
        "    error = cv2.norm(sample.corners, imgpoints, cv2.NORM_L2)/len(imgpoints)\n",
        "    if error < error_threshold:\n",
        "        names.append(sample.name)\n",
        "    # axis2d, jac = cv2.projectPoints(axis, sample.rvec, sample.tvec, mtx, dist)\n",
        "    #origin = tuple([int(v) for v in sample.corners[0].ravel()])\n",
        "    #for i in range(0, 3):\n",
        "    #    dst = cv2.line(dst, origin, tuple(\n",
        "    #        [int(v) for v in axis2d[i].ravel()]), color[i], 5)\n",
        "    lwidth = 2\n",
        "    dst = cv2.line(dst, (x, y), (x + w, y), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y), (x + w, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y + h), (x, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x, y + h), (x, y), (0, 255, 0), lwidth)\n",
        "    fig = plte.imshow(\n",
        "        dst,\n",
        "        title=f\"image {sample.name},crop[x,y,w,h]={roi},error={error}\")\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "_EAxvznllsS_"
      },
      "id": "_EAxvznllsS_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETE\n",
        "\"\"\"\n",
        "import plotly.express as plte\n",
        "import requests\n",
        "import logging\n",
        "import dataclasses\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Grid:\n",
        "    name: str\n",
        "    url: str\n",
        "    corners_x: int\n",
        "    corners_y: int\n",
        "    corners: any\n",
        "    image: any\n",
        "    obj_points: any = None\n",
        "    rvec: numpy.ndarray = None\n",
        "    tvec: numpy.ndarray = None\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "# set to None if all items are aceptable\n",
        "acepted_items = [\n",
        "    \"image0_r.jpg\",\n",
        "    \"image0_l.jpg\",\n",
        "    \"image61_r.jpg\",\n",
        "    \"image61_l.jpg\",\n",
        "    \"image68_r.jpg\",\n",
        "    \"image68_l.jpg\",\n",
        "    # \"image75_r.jpg\",\n",
        "    \"image75_l.jpg\",\n",
        "    \"image83_r.jpg\",\n",
        "    \"image83_l.jpg\",\n",
        "    #\"image84_r.jpg\",\n",
        "    #\"image84_l.jpg\",\n",
        "    # \"image89_r.jpg\",\n",
        "    #\"image89_l.jpg\",\n",
        "    #\"image91_r.jpg\",\n",
        "    #\"image91_l.jpg\"\n",
        "]\n",
        "\n",
        "sample_dataframe = pandas.read_csv('samples.csv', sep=',')\n",
        "samples: list[Grid] = []\n",
        "orig_files = []\n",
        "for index, item in sample_dataframe.iterrows():\n",
        "    item_file = item[\"image\"].lstrip(\" \")\n",
        "    url = base_url.format(item_file)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        logger.error(\"Can't read image %s from url %s\", item_file, url)\n",
        "    # Draw and display the corners\n",
        "    orig_image = load_image(response.content)\n",
        "    orig_files.append(numpy.array(orig_image))\n",
        "    if acepted_items is not None and not item_file in acepted_items:\n",
        "        logger.warning(\"Item %s is skipped because it is not in accepted list\",\n",
        "                       item_file)\n",
        "        continue\n",
        "    corners, image = get_chess_corners_from_image(\n",
        "        image=orig_image,\n",
        "        corners_x=item[\"corners_x\"],\n",
        "        corners_y=item[\"corners_y\"]\n",
        "    )\n",
        "    if corners is None:\n",
        "        logger.error(\"Can't find %d, %d conrenrs in %s\",\n",
        "                     item[\"corners_x\"], item[\"corners_y\"], item_file)\n",
        "    grid = Grid(\n",
        "        name=item_file,\n",
        "        url=url,\n",
        "        corners_x=item[\"corners_x\"],\n",
        "        corners_y=item[\"corners_y\"],\n",
        "        corners=corners,\n",
        "        image=image\n",
        "    )\n",
        "    samples.append(grid)\n",
        "\n",
        "sample_dataframe = sample_dataframe.assign(image_data=orig_files)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "A-bXJHcUVF8R"
      },
      "id": "A-bXJHcUVF8R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DELETED\n",
        "\"\"\"\n",
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "obj_points = []\n",
        "img_points = []\n",
        "objects = []\n",
        "shapes = None\n",
        "for sample in samples:\n",
        "    if sample.corners is None:\n",
        "        continue\n",
        "\n",
        "    objp = numpy.zeros((sample.corners_x*sample.corners_y,3), numpy.float32)\n",
        "    objp[:,:2] = numpy.mgrid[0:sample.corners_x,0:sample.corners_y].T.reshape(\n",
        "        -1, 2)\n",
        "    objp = objp\n",
        "    img_shape = (sample.image.shape[1], sample.image.shape[0])\n",
        "    if not shapes is None and shapes != img_shape:\n",
        "        logger.error(\n",
        "            \"Image %s has specific shape %s that is not equals to previously shapes: %s\",\n",
        "            sample.name, str(img_shape), str(shapes)\n",
        "            )\n",
        "        continue\n",
        "    if shapes is None:\n",
        "        shapes = img_shape\n",
        "    sample.obj_points = objp\n",
        "    obj_points.append(objp)\n",
        "    img_points.append(sample.corners)\n",
        "    objects.append(sample)\n",
        "\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "    obj_points, img_points, shapes, None, None)\n",
        "for i in range(0, len(objects)):\n",
        "    objects[i].rvec = rvecs[i]\n",
        "    objects[i].tvec = tvecs[i]\n",
        "ret, mtx, dist\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1X1j9pP1Xnt3"
      },
      "id": "1X1j9pP1Xnt3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "names = []\n",
        "error_threshold = 0.15\n",
        "axis = numpy.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
        "color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "undistorted_images = []\n",
        "\n",
        "for sample in samples:\n",
        "    if sample.corners is None:\n",
        "        fig = plte.imshow(sample.image, title=sample.name)\n",
        "        fig.show()\n",
        "        logger.warning(\"Image %s has no detected chessboard corners, skipping...\",\n",
        "                       sample.name)\n",
        "        continue\n",
        "    pre_dst = undistort_image(\n",
        "        image=sample.image,\n",
        "        mtx=mtx, dist=dist, new_mtx=newcameramtx,\n",
        "        canvas_w=shapes[0], canvas_h=shapes[1])\n",
        "    # crop the image\n",
        "    x, y, w, h = roi\n",
        "    dst = pre_dst # [y:y + h, x:x + w]\n",
        "    imgpoints, _ = cv2.projectPoints(\n",
        "        sample.obj_points, sample.rvec, sample.tvec, mtx, dist)\n",
        "    error = cv2.norm(sample.corners, imgpoints, cv2.NORM_L2)/len(imgpoints)\n",
        "    if error < error_threshold:\n",
        "        names.append(sample.name)\n",
        "    # axis2d, jac = cv2.projectPoints(axis, sample.rvec, sample.tvec, mtx, dist)\n",
        "    #origin = tuple([int(v) for v in sample.corners[0].ravel()])\n",
        "    #for i in range(0, 3):\n",
        "    #    dst = cv2.line(dst, origin, tuple(\n",
        "    #        [int(v) for v in axis2d[i].ravel()]), color[i], 5)\n",
        "    lwidth = 2\n",
        "    dst = cv2.line(dst, (x, y), (x + w, y), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y), (x + w, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y + h), (x, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x, y + h), (x, y), (0, 255, 0), lwidth)\n",
        "    fig = plte.imshow(\n",
        "        dst,\n",
        "        title=f\"image {sample.name},crop[x,y,w,h]={roi},error={error}\")\n",
        "    fig.show()\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NZHfpvEaDT8x"
      },
      "id": "NZHfpvEaDT8x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epipolar lines"
      ],
      "metadata": {
        "id": "vaAa3206Twko"
      },
      "id": "vaAa3206Twko"
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_descriptors(left_image: any, right_image: any\n",
        "                          ) -> tuple[any, any]:\n",
        "    sift = cv2.SIFT_create()\n",
        "    # find the keypoints and descriptors with SIFT\n",
        "    kp1, des1 = sift.detectAndCompute(left_image, None)\n",
        "    kp2, des2 = sift.detectAndCompute(right_image, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    pts1 = []\n",
        "    pts2 = []\n",
        "\n",
        "    # ratio test as per Lowe's paper\n",
        "    for i,(m,n) in enumerate(matches):\n",
        "        if m.distance < 0.8*n.distance:\n",
        "            pts2.append(kp2[m.trainIdx].pt)\n",
        "            pts1.append(kp1[m.queryIdx].pt)\n",
        "\n",
        "    return pts1, pts2"
      ],
      "metadata": {
        "id": "J-Jlda4KUv0E"
      },
      "id": "J-Jlda4KUv0E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, w, h = roi\n",
        "first = dataframe[dataframe[\"no\"] == 0]\n",
        "first_left = undistort_image(\n",
        "    image=first[first[\"type\"] == \"l\"][\"image_data\"].iloc[0],\n",
        "    mtx=mtx, dist=dist, new_mtx=newcameramtx,\n",
        "    canvas_w=shapes[0], canvas_h=shapes[1])[y:y+h,x:x+w]\n",
        "first_right = undistort_image(\n",
        "    first[first[\"type\"] == \"r\"][\"image_data\"].iloc[0],\n",
        "    mtx=mtx, dist=dist, new_mtx=newcameramtx,\n",
        "    canvas_w=shapes[0], canvas_h=shapes[1])[y:y+h,x:x+w]\n",
        "left_pts, right_pts = calculate_descriptors(left_image=first_left,\n",
        "                                            right_image=first_right)"
      ],
      "metadata": {
        "id": "7L8DSJuuV-wI"
      },
      "id": "7L8DSJuuV-wI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_matched_points(\n",
        "    left_image: numpy.ndarray,\n",
        "    right_image: numpy.ndarray,\n",
        "    left_points: numpy.ndarray,\n",
        "    right_points: numpy.ndarray\n",
        ") -> None:\n",
        "    canvas_shape = list(left_image.shape)\n",
        "    canvas_shape[1] = canvas_shape[1]*2\n",
        "    canvas = numpy.zeros(canvas_shape)\n",
        "    canvas[:, 0:left_image.shape[1], :] = left_image\n",
        "    canvas[:, left_image.shape[1]:, :] = right_image\n",
        "    for p_left, p_right in zip(left_points, right_points):\n",
        "        color = tuple(numpy.random.randint(0, 255, 3).tolist())\n",
        "        left_point = tuple(map(int, p_left))\n",
        "        canvas = cv2.circle(canvas, left_point, 5, color,-1)\n",
        "        p_right_shifted = list(p_right)\n",
        "        p_right_shifted[0] = p_right_shifted[0] + left_image.shape[1]\n",
        "        right_point = tuple(map(int, p_right_shifted))\n",
        "        canvas = cv2.circle(canvas, right_point, 5, color,-1)\n",
        "        canvas = cv2.line(canvas, left_point, right_point, (0, 255, 0), 1)\n",
        "    fig = plte.imshow(canvas)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "__5xQBT0gofE"
      },
      "id": "__5xQBT0gofE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=first_left,\n",
        "    right_image=first_right,\n",
        "    left_points=left_pts,\n",
        "    right_points=right_pts\n",
        ")"
      ],
      "metadata": {
        "id": "ESrSf3kUhdd-"
      },
      "id": "ESrSf3kUhdd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fundamental_matrix(\n",
        "    p1: numpy.ndarray, p2: numpy.ndarray\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray]:\n",
        "    p1 = numpy.int32(p1)\n",
        "    p2 = numpy.int32(p2)\n",
        "    return cv2.findFundamentalMat(p1, p2, cv2.FM_LMEDS)"
      ],
      "metadata": {
        "id": "fW3EdB5PerWI"
      },
      "id": "fW3EdB5PerWI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fm, mask = calculate_fundamental_matrix(\n",
        "    p1=left_pts, p2=right_pts\n",
        ")\n",
        "left_pts_filtered = numpy.array(left_pts)[mask.ravel()==1]\n",
        "right_pts_filtered = numpy.array(right_pts)[mask.ravel()==1]"
      ],
      "metadata": {
        "id": "lbU1UUTteLTT"
      },
      "id": "lbU1UUTteLTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=first_left,\n",
        "    right_image=first_right,\n",
        "    left_points=left_pts_filtered,\n",
        "    right_points=right_pts_filtered\n",
        ")"
      ],
      "metadata": {
        "id": "O2gexeORfsQS"
      },
      "id": "O2gexeORfsQS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stereo = cv2.StereoBM.create(numDisparities=16, blockSize=23)\n",
        "first_left_gray = cv2.cvtColor(first_left, cv2.COLOR_BGR2GRAY)\n",
        "first_right_gray = cv2.cvtColor(first_right, cv2.COLOR_BGR2GRAY)\n",
        "disparity = stereo.compute(first_left_gray, first_right_gray)\n",
        "plte.imshow(disparity).show()"
      ],
      "metadata": {
        "id": "Mgz0wnrCfv00"
      },
      "id": "Mgz0wnrCfv00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O real-samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-real-test/position.csv"
      ],
      "metadata": {
        "id": "_Vm_vOFnvjmN"
      },
      "id": "_Vm_vOFnvjmN",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}