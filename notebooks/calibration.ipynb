{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0",
      "metadata": {
        "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0"
      },
      "source": [
        "# Camera calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6468cf32-7430-49eb-8576-1f798ef0c846",
      "metadata": {
        "id": "6468cf32-7430-49eb-8576-1f798ef0c846"
      },
      "source": [
        "Notebook is based on OpenCV tutorial (https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)\n",
        "\n",
        "\n",
        "see also for visualization:\n",
        "\n",
        "https://www.rerun.io/\n",
        "\n",
        "\n",
        "online viewer:\n",
        "\n",
        "https://www.rerun.io/viewer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0",
      "metadata": {
        "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0"
      },
      "outputs": [],
      "source": [
        "!wget -O samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/position.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import logging\n",
        "import io\n",
        "import numpy\n",
        "import plotly.express as plte\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "# termination criteria\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "\n",
        "def load_image(payload: any) -> any:\n",
        "    np_image = numpy.frombuffer(payload, numpy.uint8)\n",
        "    img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_chess_corners_from_image(\n",
        "        image: any, corners_x: int, corners_y: int) -> tuple[any, any]:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find the chess board corners\n",
        "    ret, corners = cv2.findChessboardCorners(gray, (corners_x, corners_y), None)\n",
        "\n",
        "    # If found, add object points, image points (after refining them)\n",
        "    if ret != True:\n",
        "        logger.error(\"Error, grid (%d, %d) is not found in image\",\n",
        "                     corners_x, corners_y)\n",
        "        return None, gray\n",
        "\n",
        "    corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1,-1), criteria)\n",
        "    result_image = cv2.drawChessboardCorners(image, (7,7), corners, True)\n",
        "    return corners2, result_image\n",
        "\n",
        "\n",
        "def undistort_image(image: numpy.ndarray, mtx: numpy.ndarray,\n",
        "                    dist: numpy.ndarray, new_mtx: numpy.ndarray,\n",
        "                    canvas_w: int, canvas_h: int) -> numpy.ndarray:\n",
        "    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, new_mtx,\n",
        "                                             (canvas_w, canvas_h), 5)\n",
        "    return cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n"
      ],
      "metadata": {
        "id": "8cpIb1CoYF0Q"
      },
      "id": "8cpIb1CoYF0Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import logging\n",
        "import functools\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_single_image(item: pandas.Series, url_template: str) -> numpy.ndarray:\n",
        "    item_file = item[\"image\"].lstrip(\" \")\n",
        "    url = url_template.format(item_file)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        logger.error(\"Can't read image %s from url %s\", item_file, url)\n",
        "    return pandas.Series([load_image(response.content), url],\n",
        "                         index=[\"image_data\", \"url\"])"
      ],
      "metadata": {
        "id": "dkjeAK9S7l-H"
      },
      "id": "dkjeAK9S7l-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def match_points(\n",
        "        corners_x: numpy.ndarray,\n",
        "        corners_y: numpy.ndarray,\n",
        "        corners: numpy.ndarray,\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray]:\n",
        "    objp = numpy.zeros((corners_x*corners_y, 3), numpy.float32)\n",
        "    objp[:,:2] = numpy.mgrid[0:corners_x, 0:corners_y].T.reshape(-1, 2)\n",
        "    return objp\n",
        "\n",
        "\n",
        "def calculate_image_corners(\n",
        "        row: pandas.Series, ignore_list: str=None, shapes: numpy.ndarray=None,\n",
        "        image_field=\"image_data\"\n",
        ") -> pandas.Series:\n",
        "    result = pandas.Series({\n",
        "        \"corners\": None, \"chess_image\": None, \"object_points\": None})\n",
        "    if ignore_list is not None and row.image in ignore_list:\n",
        "        return result\n",
        "\n",
        "    corners, image = get_chess_corners_from_image(\n",
        "        image=numpy.copy(row[image_field]),\n",
        "        corners_x=row.corners_x,\n",
        "        corners_y=row.corners_y\n",
        "    )\n",
        "\n",
        "    img_shape = (row.image_data.shape[1], row.image_data.shape[0])\n",
        "    #if shapes != img_shape:\n",
        "    #    logger.error(\n",
        "    #        \"Image %s has specific shape %s that is not equals to previously shapes: %s\",\n",
        "    #        sample.name, str(img_shape), str(shapes)\n",
        "    #        )\n",
        "    #    return pandas.Series([None, None, None], index=[\"obj_points\", \"image_points\"])\n",
        "\n",
        "    if corners is None:\n",
        "        objp = None\n",
        "        logger.error(\"Can't find %d, %d conrenrs in %s\",\n",
        "                     row.corners_x, row.corners_y, row.image)\n",
        "    else:\n",
        "        objp = match_points(corners_x=row.corners_x,\n",
        "                            corners_y=row.corners_y,\n",
        "                            corners=corners)\n",
        "\n",
        "    result.corners = corners\n",
        "    result.chess_image = image\n",
        "    result.object_points= objp\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "HvPyuScqRUrK"
      },
      "id": "HvPyuScqRUrK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def undistort_image_from_row(\n",
        "        row: pandas.Series,\n",
        "        camera_matrix: numpy.ndarray,\n",
        "        distortion_matrix: numpy.ndarray,\n",
        "        new_camera_matrix: numpy.ndarray,\n",
        "        region: tuple[int, int, int, int]\n",
        ") -> pandas.Series:\n",
        "    axis = numpy.float32([[3, 0, 0], [0, 3, 0], [0, 0, -3]]).reshape(-1, 3)\n",
        "    color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "    result = pandas.Series({\"undistorted\": None, \"undistorted_debug\": None,\n",
        "                            \"reconstructed_points\": None, \"imgpoints\": None})\n",
        "    if row[\"corners\"] is None:\n",
        "        logger.warning(\"Image %s has no detected chessboard corners, skipping...\",\n",
        "                       row[\"image\"])\n",
        "        return result\n",
        "\n",
        "    pre_dst = undistort_image(\n",
        "        image=row[\"image_data\"],\n",
        "        mtx=camera_matrix, dist=distortion_matrix,\n",
        "        new_mtx=new_camera_matrix,\n",
        "        canvas_w=row[\"image_data\"].shape[1], canvas_h=row[\"image_data\"].shape[0])\n",
        "    # crop the image\n",
        "    x, y, w, h = roi\n",
        "    dst = numpy.copy(pre_dst) # [y:y + h, x:x + w]\n",
        "    imgpoints, _ = cv2.projectPoints(\n",
        "        row[\"object_points\"], row[\"rvec\"], row[\"tvec\"],\n",
        "        camera_matrix, distortion_matrix)\n",
        "    error = cv2.norm(row[\"corners\"], imgpoints, cv2.NORM_L2)/len(imgpoints)\n",
        "    #if error < error_threshold:\n",
        "    #    names.append(sample.name)\n",
        "    # axis2d, jac = cv2.projectPoints(axis, sample.rvec, sample.tvec, mtx, dist)\n",
        "    #origin = tuple([int(v) for v in sample.corners[0].ravel()])\n",
        "    #for i in range(0, 3):\n",
        "    #    dst = cv2.line(dst, origin, tuple(\n",
        "    #        [int(v) for v in axis2d[i].ravel()]), color[i], 5)\n",
        "    lwidth = 2\n",
        "    dst = cv2.line(dst, (x, y), (x + w, y), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y), (x + w, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y + h), (x, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x, y + h), (x, y), (0, 255, 0), lwidth)\n",
        "\n",
        "    result[\"undistorted_debug\"] = dst\n",
        "    result[\"undistorted\"] = pre_dst\n",
        "    result[\"reconstructed_points\"] = imgpoints\n",
        "    result[\"error\"] = error\n",
        "\n",
        "    return result\n",
        "\n",
        "def draw_image_sequence(*args, axis=1) -> numpy.ndarray:\n",
        "    if len(args) == 0:\n",
        "        return numpy.ndarray()\n",
        "\n",
        "    w = args[0].shape[1]\n",
        "    h = args[0].shape[0]\n",
        "    canvas_shape = list(args[0].shape)\n",
        "    canvas_shape[axis] = canvas_shape[axis]*len(args)\n",
        "    canvas = numpy.zeros(canvas_shape)\n",
        "    for i in range(0, len(args)):\n",
        "        if axis == 1:\n",
        "            canvas[:, i*w:(i + 1)*w, :] = args[i]\n",
        "        else:\n",
        "            canvas[i*w:(i + 1)*w, :, :] = args[i]\n",
        "\n",
        "    return canvas"
      ],
      "metadata": {
        "id": "_EAxvznllsS_"
      },
      "id": "_EAxvznllsS_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/{}\"\n",
        "ignore_list = [\n",
        "    \"image75_r.jpg\", \"image84_r.jpg\",\n",
        "    \"image84_l.jpg\", \"image89_r.jpg\",\n",
        "    \"image89_l.jpg\", \"image91_r.jpg\",\n",
        "    \"image91_l.jpg\"\n",
        "]\n",
        "\n",
        "dataframe = pandas.read_csv(\"samples.csv\", sep=',')\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            load_single_image,\n",
        "            url_template=base_url),\n",
        "        axis=1)\n",
        ")\n",
        "shapes = dataframe[\"image_data\"].apply(lambda x: x.shape).unique()\n",
        "if shapes.shape[0] != 1:\n",
        "    logger.error(\"More than one unique image sizes were found: %s\",\n",
        "                 str(shapes))\n",
        "shapes = (shapes[0][1], shapes[0][0])\n",
        "\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            calculate_image_corners,\n",
        "            ignore_list=ignore_list,\n",
        "            shapes=None),\n",
        "        axis=1)\n",
        ")\n",
        "\n",
        "filtered = dataframe[~dataframe[\"image\"].isin(ignore_list)]\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "    filtered[\"object_points\"].tolist(),\n",
        "    filtered[\"corners\"].tolist(), shapes,\n",
        "    None, None)\n",
        "filtered = filtered.assign(rvec=rvecs, tvec=tvecs)\n",
        "dataframe = dataframe.join(filtered[[\"rvec\", \"tvec\"]])\n",
        "\n",
        "w = shapes[0]\n",
        "h = shapes[1]\n",
        "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
        "(roi, newcameramtx)\n",
        "\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            undistort_image_from_row,\n",
        "            camera_matrix=mtx,\n",
        "            distortion_matrix=dist,\n",
        "            new_camera_matrix=newcameramtx,\n",
        "            region=roi\n",
        "        ), axis=1\n",
        "    )\n",
        ")\n",
        "x, y, w, h = roi\n",
        "dataframe.undistorted = dataframe.apply(\n",
        "    lambda row: row.undistorted[\n",
        "        y:y + h, x:x + w] if row.undistorted is not None else None\n",
        "    , axis=1)\n",
        "dataframe[[\"image\", \"error\"]]\n",
        "\n",
        "filtered_undistorted = dataframe[~dataframe[\"image\"].isin(ignore_list)]\n",
        "dataframe = dataframe.join(\n",
        "    filtered_undistorted.apply(functools.partial(\n",
        "        calculate_image_corners, image_field=\"undistorted\"\n",
        "    ), axis=1), rsuffix=\"_undistorted\")\n",
        "dataframe.columns"
      ],
      "metadata": {
        "id": "UqzgtBZZDTps"
      },
      "id": "UqzgtBZZDTps",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plte.imshow(dataframe.chess_image.iloc[0]).show()\n",
        "plte.imshow(dataframe.undistorted.iloc[0]).show()"
      ],
      "metadata": {
        "id": "pVg5wilwYsui"
      },
      "id": "pVg5wilwYsui",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stereo experiments"
      ],
      "metadata": {
        "id": "vaAa3206Twko"
      },
      "id": "vaAa3206Twko"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[stereoCalibrate](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga9d2539c1ebcda647487a616bdf0fc716) - calculates transformations to locate points of one camera's image on another one based on known pattern.\n",
        "\n",
        "[stereoRectify](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga617b1685d4059c6040827800e72ad2b6) - calculates a transformation to represent images from stereo pair on a single plane."
      ],
      "metadata": {
        "id": "UUXE_t2d8w02"
      },
      "id": "UUXE_t2d8w02"
    },
    {
      "cell_type": "code",
      "source": [
        "stereodata = dataframe[dataframe.type == \"r\"].merge(\n",
        "    dataframe[dataframe.type == \"l\"], on=\"no\", suffixes=[\"_right\", \"_left\"])\n",
        "stereodata.columns"
      ],
      "metadata": {
        "id": "0_oxSEuuqLjP"
      },
      "id": "0_oxSEuuqLjP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stereo_calib_data = stereodata[\n",
        "    (~stereodata.corners_left.isnull()) & (~stereodata.corners_right.isnull())]\n",
        "stereo_calib_data = stereo_calib_data[\n",
        "    (stereo_calib_data.object_points_left.apply(lambda x: x.shape)\n",
        "     ==stereo_calib_data.object_points_right.apply(lambda x: x.shape))\n",
        "]\n",
        "len(stereo_calib_data)"
      ],
      "metadata": {
        "id": "lcBlsLI7J44i"
      },
      "id": "lcBlsLI7J44i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "calib_data = cv2.stereoCalibrate(\n",
        "    stereo_calib_data.object_points_undistorted_left.iloc[0],\n",
        "    stereo_calib_data.corners_undistorted_left.iloc[0],\n",
        "    stereo_calib_data.corners_undistorted_right.iloc[0],\n",
        "\n",
        ")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4JXqSsBdLPHv"
      },
      "id": "4JXqSsBdLPHv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_descriptors(left_image: any, right_image: any\n",
        "                          ) -> tuple[any, any]:\n",
        "    sift = cv2.SIFT_create()\n",
        "    # find the keypoints and descriptors with SIFT\n",
        "    kp1, des1 = sift.detectAndCompute(left_image, None)\n",
        "    kp2, des2 = sift.detectAndCompute(right_image, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    pts1 = []\n",
        "    pts2 = []\n",
        "\n",
        "    # ratio test as per Lowe's paper\n",
        "    for i,(m,n) in enumerate(matches):\n",
        "        if m.distance < 0.8*n.distance:\n",
        "            pts2.append(kp2[m.trainIdx].pt)\n",
        "            pts1.append(kp1[m.queryIdx].pt)\n",
        "\n",
        "    return pts1, pts2"
      ],
      "metadata": {
        "id": "J-Jlda4KUv0E"
      },
      "id": "J-Jlda4KUv0E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, w, h = roi\n",
        "num = 0\n",
        "left_pts, right_pts = calculate_descriptors(left_image=stereodata.undistorted_left.iloc[num],\n",
        "                                            right_image=stereodata.undistorted_left.iloc[num])"
      ],
      "metadata": {
        "id": "7L8DSJuuV-wI"
      },
      "id": "7L8DSJuuV-wI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def draw_matched_points(\n",
        "    left_image: numpy.ndarray,\n",
        "    right_image: numpy.ndarray,\n",
        "    left_points: numpy.ndarray,\n",
        "    right_points: numpy.ndarray\n",
        ") -> None:\n",
        "    canvas_shape = list(left_image.shape)\n",
        "    canvas_shape[1] = canvas_shape[1]*2\n",
        "    canvas = numpy.zeros(canvas_shape)\n",
        "    canvas[:, 0:left_image.shape[1], :] = left_image\n",
        "    canvas[:, left_image.shape[1]:, :] = right_image\n",
        "    for p_left, p_right in zip(left_points, right_points):\n",
        "        color = tuple(numpy.random.randint(0, 255, 3).tolist())\n",
        "        left_point = tuple(map(int, p_left))\n",
        "        canvas = cv2.circle(canvas, left_point, 5, color,-1)\n",
        "        p_right_shifted = list(p_right)\n",
        "        p_right_shifted[0] = p_right_shifted[0] + left_image.shape[1]\n",
        "        right_point = tuple(map(int, p_right_shifted))\n",
        "        canvas = cv2.circle(canvas, right_point, 5, color,-1)\n",
        "        canvas = cv2.line(canvas, left_point, right_point, (0, 255, 0), 1)\n",
        "    fig = plte.imshow(canvas)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "__5xQBT0gofE"
      },
      "id": "__5xQBT0gofE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=stereodata.undistorted_left.iloc[num],\n",
        "    right_image=stereodata.undistorted_right.iloc[num],\n",
        "    left_points=left_pts,\n",
        "    right_points=right_pts\n",
        ")"
      ],
      "metadata": {
        "id": "ESrSf3kUhdd-"
      },
      "id": "ESrSf3kUhdd-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fundamental_matrix(\n",
        "    p1: numpy.ndarray, p2: numpy.ndarray\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray]:\n",
        "    p1 = numpy.int32(p1)\n",
        "    p2 = numpy.int32(p2)\n",
        "    return cv2.findFundamentalMat(p1, p2, cv2.FM_LMEDS)"
      ],
      "metadata": {
        "id": "fW3EdB5PerWI"
      },
      "id": "fW3EdB5PerWI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fm, mask = calculate_fundamental_matrix(\n",
        "    p1=left_pts, p2=right_pts\n",
        ")\n",
        "left_pts_filtered = numpy.array(left_pts)[mask.ravel()==1]\n",
        "right_pts_filtered = numpy.array(right_pts)[mask.ravel()==1]"
      ],
      "metadata": {
        "id": "lbU1UUTteLTT"
      },
      "id": "lbU1UUTteLTT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=stereodata.undistorted_left.iloc[num],\n",
        "    right_image=stereodata.undistorted_right.iloc[num],\n",
        "    left_points=left_pts_filtered,\n",
        "    right_points=right_pts_filtered\n",
        ")"
      ],
      "metadata": {
        "id": "O2gexeORfsQS"
      },
      "id": "O2gexeORfsQS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stereo = cv2.StereoBM.create(numDisparities=16, blockSize=15)\n",
        "first_left_gray = cv2.cvtColor(stereodata.undistorted_left.iloc[num], cv2.COLOR_BGR2GRAY)\n",
        "first_right_gray = cv2.cvtColor(stereodata.undistorted_right.iloc[num], cv2.COLOR_BGR2GRAY)\n",
        "disparity = stereo.compute(first_left_gray, first_right_gray)\n",
        "plte.imshow(disparity).show()"
      ],
      "metadata": {
        "id": "Mgz0wnrCfv00"
      },
      "id": "Mgz0wnrCfv00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web camera experiments"
      ],
      "metadata": {
        "id": "3fI4ImiCkCCy"
      },
      "id": "3fI4ImiCkCCy"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O real-samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-real-test/position.csv"
      ],
      "metadata": {
        "id": "_Vm_vOFnvjmN"
      },
      "id": "_Vm_vOFnvjmN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-real-test/{}\"\n",
        "dataframe = pandas.read_csv(\"real-samples.csv\", sep=',')\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            load_single_image,\n",
        "            url_template=base_url),\n",
        "        axis=1)\n",
        ")\n",
        "plte.imshow(draw_image_sequence(dataframe.image_data.iloc[1], dataframe.image_data.iloc[0]))"
      ],
      "metadata": {
        "id": "WmkIorldgyqo"
      },
      "id": "WmkIorldgyqo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_pts, right_pts = calculate_descriptors(left_image=dataframe.image_data.iloc[1],\n",
        "                                            right_image=dataframe.image_data.iloc[0])"
      ],
      "metadata": {
        "id": "cYbA2tZW__sf"
      },
      "id": "cYbA2tZW__sf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=dataframe.image_data.iloc[1],\n",
        "    right_image=dataframe.image_data.iloc[0],\n",
        "    left_points=left_pts,\n",
        "    right_points=right_pts\n",
        ")"
      ],
      "metadata": {
        "id": "Apd7_QDEAJHT"
      },
      "id": "Apd7_QDEAJHT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fm, mask = calculate_fundamental_matrix(\n",
        "    p1=left_pts, p2=right_pts\n",
        ")\n",
        "left_pts_filtered = numpy.array(left_pts)[mask.ravel()==1]\n",
        "right_pts_filtered = numpy.array(right_pts)[mask.ravel()==1]"
      ],
      "metadata": {
        "id": "zFvi69YUAS3C"
      },
      "id": "zFvi69YUAS3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=dataframe.image_data.iloc[1],\n",
        "    right_image=dataframe.image_data.iloc[0],\n",
        "    left_points=left_pts_filtered,\n",
        "    right_points=right_pts_filtered\n",
        ")"
      ],
      "metadata": {
        "id": "_VHhmbv2Aj3b"
      },
      "id": "_VHhmbv2Aj3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rYN5u9N3Anc_"
      },
      "id": "rYN5u9N3Anc_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}