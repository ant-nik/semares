{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0",
      "metadata": {
        "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0"
      },
      "source": [
        "# Camera calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6468cf32-7430-49eb-8576-1f798ef0c846",
      "metadata": {
        "id": "6468cf32-7430-49eb-8576-1f798ef0c846"
      },
      "source": [
        "Notebook is based on OpenCV tutorial (https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)\n",
        "\n",
        "\n",
        "see also for visualization:\n",
        "\n",
        "https://www.rerun.io/\n",
        "\n",
        "\n",
        "online viewer:\n",
        "\n",
        "https://www.rerun.io/viewer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preliminary code"
      ],
      "metadata": {
        "id": "AMW_lIAtTL23"
      },
      "id": "AMW_lIAtTL23"
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import logging\n",
        "import io\n",
        "import numpy\n",
        "import plotly.express as plte\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "# termination criteria\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "\n",
        "def load_image(payload: any) -> any:\n",
        "    np_image = numpy.frombuffer(payload, numpy.uint8)\n",
        "    img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def find_chess(image: any, corners_x: int, corners_y: int) -> numpy.ndarray:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find the chess board corners\n",
        "    ret, corners = cv2.findChessboardCorners(gray, (corners_x, corners_y), None)\n",
        "\n",
        "    # If found, add object points, image points (after refining them)\n",
        "    if ret != True:\n",
        "        logger.error(\"Error, grid (%d, %d) is not found in image\",\n",
        "                     corners_x, corners_y)\n",
        "        return None\n",
        "\n",
        "    corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1,-1), criteria)\n",
        "\n",
        "    return corners2\n",
        "\n",
        "\n",
        "def get_chess_corners_from_image(\n",
        "        image: any, corners_x: int, corners_y: int) -> tuple[any, any]:\n",
        "    corners = find_chess(image=image, corners_x=corners_x,\n",
        "                         corners_y=corners_y)\n",
        "    if corners is None:\n",
        "        return None, image\n",
        "    result_image = cv2.drawChessboardCorners(image, (corners_x, corners_x),\n",
        "                                             corners, True)\n",
        "    return corners, result_image\n",
        "\n",
        "\n",
        "def undistort_image(image: numpy.ndarray, mtx: numpy.ndarray,\n",
        "                    dist: numpy.ndarray, new_mtx: numpy.ndarray,\n",
        "                    canvas_w: int, canvas_h: int) -> numpy.ndarray:\n",
        "    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, new_mtx,\n",
        "                                             (canvas_w, canvas_h), 5)\n",
        "    return cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n"
      ],
      "metadata": {
        "id": "8cpIb1CoYF0Q"
      },
      "id": "8cpIb1CoYF0Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import logging\n",
        "import functools\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_single_image(item: pandas.Series, url_template: str) -> numpy.ndarray:\n",
        "    item_file = item[\"image\"].lstrip(\" \")\n",
        "    url = url_template.format(item_file)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        logger.error(\"Can't read image %s from url %s\", item_file, url)\n",
        "    return pandas.Series([load_image(response.content), url],\n",
        "                         index=[\"image_data\", \"url\"])"
      ],
      "metadata": {
        "id": "dkjeAK9S7l-H"
      },
      "id": "dkjeAK9S7l-H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def match_points(\n",
        "        corners_x: int,\n",
        "        corners_y: int,\n",
        "        corners: numpy.ndarray,\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray]:\n",
        "    objp = numpy.zeros((corners_x*corners_y, 3), numpy.float32)\n",
        "    objp[:,:2] = numpy.mgrid[0:corners_x, 0:corners_y].T.reshape(-1, 2)\n",
        "    return objp\n",
        "\n",
        "\n",
        "def calculate_image_corners(\n",
        "        row: pandas.Series, ignore_list: str=None, shapes: numpy.ndarray=None,\n",
        "        image_field=\"image_data\"\n",
        ") -> pandas.Series:\n",
        "    result = pandas.Series({\n",
        "        \"corners\": None, \"chess_image\": None, \"object_points\": None})\n",
        "    if ignore_list is not None and row.image in ignore_list:\n",
        "        return result\n",
        "\n",
        "    corners, image = get_chess_corners_from_image(\n",
        "        image=numpy.copy(row[image_field]),\n",
        "        corners_x=int(row.corners_x),\n",
        "        corners_y=int(row.corners_y)\n",
        "    )\n",
        "\n",
        "    img_shape = (row.image_data.shape[1], row.image_data.shape[0])\n",
        "\n",
        "    if corners is None:\n",
        "        objp = None\n",
        "        logger.error(\"Can't find %d, %d conrenrs in %s\",\n",
        "                     row.corners_x, row.corners_y, row.image)\n",
        "    else:\n",
        "        objp = match_points(corners_x=int(row.corners_x),\n",
        "                            corners_y=int(row.corners_y),\n",
        "                            corners=corners)\n",
        "\n",
        "    result.corners = corners\n",
        "    result.chess_image = image\n",
        "    result.object_points= objp\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "HvPyuScqRUrK"
      },
      "id": "HvPyuScqRUrK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def undistort_image_from_row(\n",
        "        row: pandas.Series,\n",
        "        camera_matrix: numpy.ndarray,\n",
        "        distortion_matrix: numpy.ndarray,\n",
        "        new_camera_matrix: numpy.ndarray,\n",
        "        region: tuple[int, int, int, int]\n",
        ") -> pandas.Series:\n",
        "    axis = numpy.float32([[3, 0, 0], [0, 3, 0], [0, 0, -3]]).reshape(-1, 3)\n",
        "    color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "    result = pandas.Series({\"undistorted\": None, \"undistorted_debug\": None,\n",
        "                            \"reconstructed_points\": None, \"imgpoints\": None})\n",
        "    if row[\"corners\"] is None or row[\"corners\"] is numpy.nan:\n",
        "        logger.warning(\"Image %s has no detected chessboard corners, skipping...\",\n",
        "                       row[\"image\"])\n",
        "        return result\n",
        "\n",
        "    pre_dst = undistort_image(\n",
        "        image=row[\"image_data\"],\n",
        "        mtx=camera_matrix, dist=distortion_matrix,\n",
        "        new_mtx=new_camera_matrix,\n",
        "        canvas_w=row[\"image_data\"].shape[1], canvas_h=row[\"image_data\"].shape[0])\n",
        "    # crop the image\n",
        "    x, y, w, h = region\n",
        "    dst = numpy.copy(pre_dst) # [y:y + h, x:x + w]\n",
        "    imgpoints, _ = cv2.projectPoints(\n",
        "        row[\"object_points\"], row[\"rvec\"], row[\"tvec\"],\n",
        "        camera_matrix, distortion_matrix)\n",
        "    error = cv2.norm(row[\"corners\"], imgpoints, cv2.NORM_L2)/len(imgpoints)\n",
        "    lwidth = 2\n",
        "    dst = cv2.line(dst, (x, y), (x + w, y), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y), (x + w, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y + h), (x, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x, y + h), (x, y), (0, 255, 0), lwidth)\n",
        "\n",
        "    result[\"undistorted_debug\"] = dst\n",
        "    result[\"undistorted\"] = pre_dst\n",
        "    result[\"reconstructed_points\"] = imgpoints\n",
        "    result[\"error\"] = error\n",
        "\n",
        "    return result\n",
        "\n",
        "def draw_image_sequence(*args, axis=1) -> numpy.ndarray:\n",
        "    if len(args) == 0:\n",
        "        return numpy.ndarray()\n",
        "\n",
        "    w = args[0].shape[1]\n",
        "    h = args[0].shape[0]\n",
        "    canvas_shape = list(args[0].shape)\n",
        "    canvas_shape[axis] = canvas_shape[axis]*len(args)\n",
        "    canvas = numpy.zeros(canvas_shape)\n",
        "    for i in range(0, len(args)):\n",
        "        if axis == 1:\n",
        "            canvas[:, i*w:(i + 1)*w, :] = args[i]\n",
        "        else:\n",
        "            canvas[i*w:(i + 1)*w, :, :] = args[i]\n",
        "\n",
        "    return canvas"
      ],
      "metadata": {
        "id": "_EAxvznllsS_"
      },
      "id": "_EAxvznllsS_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_fundamental_matrix(\n",
        "    p1: numpy.ndarray, p2: numpy.ndarray\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray]:\n",
        "    p1 = numpy.int32(p1)\n",
        "    p2 = numpy.int32(p2)\n",
        "    return cv2.findFundamentalMat(p1, p2, cv2.FM_LMEDS)\n",
        "\n",
        "\n",
        "def draw_matched_points(\n",
        "    left_image: numpy.ndarray,\n",
        "    right_image: numpy.ndarray,\n",
        "    left_points: numpy.ndarray,\n",
        "    right_points: numpy.ndarray\n",
        ") -> None:\n",
        "    canvas_shape = list(left_image.shape)\n",
        "    canvas_shape[1] = canvas_shape[1]*2\n",
        "    canvas = numpy.zeros(canvas_shape)\n",
        "    canvas[:, 0:left_image.shape[1], :] = left_image\n",
        "    canvas[:, left_image.shape[1]:, :] = right_image\n",
        "    for p_left, p_right in zip(left_points, right_points):\n",
        "        color = tuple(numpy.random.randint(0, 255, 3).tolist())\n",
        "        left_point = tuple(map(int, p_left))\n",
        "        canvas = cv2.circle(canvas, left_point, 5, color,-1)\n",
        "        p_right_shifted = list(p_right)\n",
        "        p_right_shifted[0] = p_right_shifted[0] + left_image.shape[1]\n",
        "        right_point = tuple(map(int, p_right_shifted))\n",
        "        canvas = cv2.circle(canvas, right_point, 5, color,-1)\n",
        "        canvas = cv2.line(canvas, left_point, right_point, (0, 255, 0), 1)\n",
        "    fig = plte.imshow(canvas)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "NHGnNzgyDfqH"
      },
      "id": "NHGnNzgyDfqH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_norm(vector: numpy.ndarray) -> float:\n",
        "    return numpy.linalg.norm(vector, ord=2)\n",
        "\n",
        "\n",
        "def calculate_angle(a_vector: numpy.ndarray, b_vector: numpy.ndarray) -> float:\n",
        "    a_norm = calculate_norm(a_vector)\n",
        "    b_norm = calculate_norm(b_vector)\n",
        "    return numpy.arccos(sum(a_vector * b_vector)/(a_norm * b_norm))*180/numpy.pi\n",
        "\n"
      ],
      "metadata": {
        "id": "nWelkK3SJay3"
      },
      "id": "nWelkK3SJay3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def calculate_sift_descriptors(image: any) -> tuple[any, any]:\n",
        "    sift = cv2.SIFT_create()\n",
        "    # find the keypoints and descriptors with SIFT\n",
        "    return sift.detectAndCompute(image, None)\n",
        "\n",
        "\n",
        "def calculate_orb_descriptors(image: numpy.ndarray) -> tuple[any, any]:\n",
        "    orb = cv.ORB_create()\n",
        "    # find the keypoints with ORB\n",
        "    kp = orb.detect(image, None)\n",
        "    # compute the descriptors with ORB\n",
        "    kp, des = orb.compute(image, kp)\n",
        "\n",
        "    return kp, des\n",
        "\n",
        "\n",
        "def calculate_match_points(\n",
        "        kp1: numpy.ndarray,\n",
        "        des1: numpy.ndarray,\n",
        "        kp2: numpy.ndarray,\n",
        "        des2: numpy.ndarray) -> tuple[list, list]:\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    pts1 = []\n",
        "    pts2 = []\n",
        "\n",
        "    # ratio test as per Lowe's paper\n",
        "    for i,(m,n) in enumerate(matches):\n",
        "        if m.distance < 0.8*n.distance:\n",
        "            pts2.append(kp2[m.trainIdx].pt)\n",
        "            pts1.append(kp1[m.queryIdx].pt)\n",
        "\n",
        "    return pts1, pts2"
      ],
      "metadata": {
        "id": "cAZpmyErOLS3"
      },
      "id": "cAZpmyErOLS3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "bbOs50qnAAQ8"
      },
      "id": "bbOs50qnAAQ8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0"
      },
      "outputs": [],
      "source": [
        "!wget -O samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/position.csv"
      ],
      "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0"
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/{}\"\n",
        "ignore_list = [\n",
        "    \"image75_r.jpg\", \"image84_r.jpg\",\n",
        "    \"image84_l.jpg\", \"image89_r.jpg\",\n",
        "    \"image89_l.jpg\", \"image91_r.jpg\",\n",
        "    \"image91_l.jpg\", \"image36_r.jpg\",\n",
        "    \"image36_l.jpg\"\n",
        "]\n",
        "\n",
        "dataframe = pandas.read_csv(\"samples.csv\", sep=',')\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            load_single_image,\n",
        "            url_template=base_url),\n",
        "        axis=1)\n",
        ")"
      ],
      "metadata": {
        "id": "UqzgtBZZDTps"
      },
      "id": "UqzgtBZZDTps",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single camera calibration"
      ],
      "metadata": {
        "id": "62JP-qwMAeTh"
      },
      "id": "62JP-qwMAeTh"
    },
    {
      "cell_type": "code",
      "source": [
        "# %debug\n",
        "shapes = dataframe[\"image_data\"].apply(lambda x: x.shape).unique()\n",
        "if shapes.shape[0] != 1:\n",
        "    logger.error(\"More than one unique image sizes were found: %s\",\n",
        "                 str(shapes))\n",
        "shapes = (shapes[0][1], shapes[0][0])\n",
        "\n",
        "filtered = dataframe[~dataframe[\"image\"].isin(ignore_list)]\n",
        "dataframe = dataframe.join(\n",
        "    filtered.apply(\n",
        "        functools.partial(\n",
        "            calculate_image_corners,\n",
        "            ignore_list=ignore_list,\n",
        "            shapes=None),\n",
        "        axis=1)\n",
        ")\n",
        "\n",
        "filtered = dataframe[~dataframe[\"image\"].isin(ignore_list)]\n",
        "\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "    filtered[\"object_points\"].tolist(),\n",
        "    filtered[\"corners\"].tolist(), shapes,\n",
        "    None, None)\n",
        "filtered = filtered.assign(rvec=rvecs, tvec=tvecs)\n",
        "dataframe = dataframe.join(filtered[[\"rvec\", \"tvec\"]])\n",
        "\n",
        "w = shapes[0]\n",
        "h = shapes[1]\n",
        "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
        "(roi, newcameramtx)"
      ],
      "metadata": {
        "id": "W21RhpIkAhUK"
      },
      "id": "W21RhpIkAhUK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered[\"object_points\"]"
      ],
      "metadata": {
        "id": "p_sQGo3kf-Rt"
      },
      "id": "p_sQGo3kf-Rt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %debug\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            undistort_image_from_row,\n",
        "            camera_matrix=mtx,\n",
        "            distortion_matrix=dist,\n",
        "            new_camera_matrix=newcameramtx,\n",
        "            region=roi\n",
        "        ), axis=1\n",
        "    )\n",
        ")\n",
        "x, y, w, h = roi\n",
        "dataframe.undistorted = dataframe.apply(\n",
        "    lambda row: row.undistorted[\n",
        "        y:y + h, x:x + w] if row.undistorted is not None else None\n",
        "    , axis=1)\n",
        "dataframe[[\"image\", \"error\"]]\n",
        "\n",
        "filtered_undistorted = dataframe[~dataframe[\"image\"].isin(ignore_list)]\n",
        "dataframe = dataframe.join(\n",
        "    filtered_undistorted.apply(functools.partial(\n",
        "        calculate_image_corners, image_field=\"undistorted\"\n",
        "    ), axis=1), rsuffix=\"_undistorted\")\n",
        "dataframe.columns"
      ],
      "metadata": {
        "id": "yFZFLNRWf0AO"
      },
      "id": "yFZFLNRWf0AO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plte.imshow(dataframe.chess_image.iloc[0]).show()\n",
        "plte.imshow(dataframe.undistorted.iloc[0]).show()"
      ],
      "metadata": {
        "id": "pVg5wilwYsui"
      },
      "id": "pVg5wilwYsui",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stereo pair calibration"
      ],
      "metadata": {
        "id": "vaAa3206Twko"
      },
      "id": "vaAa3206Twko"
    },
    {
      "cell_type": "markdown",
      "source": [
        "[stereoCalibrate](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga9d2539c1ebcda647487a616bdf0fc716) - calculates transformations to locate points of one camera's image on another one based on known pattern.\n",
        "\n",
        "[stereoRectify](https://docs.opencv.org/4.x/d9/d0c/group__calib3d.html#ga617b1685d4059c6040827800e72ad2b6) - calculates a transformation to represent images from stereo pair on a single plane.\n",
        "\n",
        "[C++ example](https://github.com/LiliMeng/Build3dModel/blob/master/build3dmodel.cpp) - stereo camera calibration.\n",
        "\n",
        "[C++ example](https://github.com/jhicks256/OpenCV-Samples/blob/ab96b66f15bca8798c56e6ce0adf8b31ba957616/stereo_match.cpp#L202) - stereo images match.\n",
        "\n",
        "### Stereo calibration and depth estimation\n",
        "\n",
        "cameraCalibration --> stereoCalibtation --> stereoRectify"
      ],
      "metadata": {
        "id": "UUXE_t2d8w02"
      },
      "id": "UUXE_t2d8w02"
    },
    {
      "cell_type": "code",
      "source": [
        "stereodata = dataframe[dataframe.type == \"r\"].merge(\n",
        "    dataframe[dataframe.type == \"l\"], on=\"no\", suffixes=[\"_right\", \"_left\"])\n",
        "stereodata.columns"
      ],
      "metadata": {
        "id": "0_oxSEuuqLjP"
      },
      "id": "0_oxSEuuqLjP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stereo_calib_data = stereodata[\n",
        "    (~stereodata.corners_left.isnull()) & (~stereodata.corners_right.isnull())]\n",
        "stereo_calib_data = stereo_calib_data[\n",
        "    (stereo_calib_data.object_points_left.apply(lambda x: x.shape)\n",
        "     ==stereo_calib_data.object_points_right.apply(lambda x: x.shape))\n",
        "]\n",
        "len(stereo_calib_data)"
      ],
      "metadata": {
        "id": "lcBlsLI7J44i"
      },
      "id": "lcBlsLI7J44i",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stereocalibration_criteria = (cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 100, 1e-5)\n",
        "stereocalibration_flags = cv2.CALIB_FIX_INTRINSIC\n",
        "scalib_results = pandas.Series(cv2.stereoCalibrate(\n",
        "    numpy.array([stereo_calib_data.object_points_left.iloc[0]]),\n",
        "    numpy.array([stereo_calib_data.corners_left.iloc[0]]),\n",
        "    numpy.array([stereo_calib_data.corners_right.iloc[0]]),\n",
        "    cameraMatrix1=mtx,\n",
        "    cameraMatrix2=mtx,\n",
        "    distCoeffs1=dist,\n",
        "    distCoeffs2=dist,\n",
        "    imageSize=shapes,\n",
        "    criteria=stereocalibration_criteria, flags = stereocalibration_flags\n",
        "), index=[\"error\", \"camera_matrix_left\", \"dist_coeffs_left\",\n",
        "          \"camera_matrix_right\", \"dist_coeffs_right\", \"R\", \"T\", \"E\", \"F\"])\n",
        "scalib_results"
      ],
      "metadata": {
        "id": "4JXqSsBdLPHv"
      },
      "id": "4JXqSsBdLPHv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "srect_results = pandas.Series(cv2.stereoRectify(\n",
        "    cameraMatrix1=scalib_results.camera_matrix_left,\n",
        "    distCoeffs1=scalib_results.dist_coeffs_left,\n",
        "    cameraMatrix2=scalib_results.camera_matrix_right,\n",
        "    distCoeffs2=scalib_results.dist_coeffs_right,\n",
        "    imageSize=shapes,\n",
        "    R=scalib_results.R, T=scalib_results[\"T\"],\n",
        "    flags=cv2.CALIB_ZERO_DISPARITY\n",
        "), index=[\"R1\", \"R2\", \"P1\", \"P2\", \"Q\", \"validPixROI1\", \"validPixROI\"])\n",
        "srect_results"
      ],
      "metadata": {
        "id": "nxwno7xb094N"
      },
      "id": "nxwno7xb094N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test stereo image rectification"
      ],
      "metadata": {
        "id": "fyljkM6V94l0"
      },
      "id": "fyljkM6V94l0"
    },
    {
      "cell_type": "code",
      "source": [
        "left_map1, left_map2 = cv2.initUndistortRectifyMap(\n",
        "    cameraMatrix=scalib_results.camera_matrix_left,\n",
        "    distCoeffs=scalib_results.dist_coeffs_left,\n",
        "    R=srect_results.R1,\n",
        "    newCameraMatrix=srect_results.P1, size=shapes, m1type=cv2.CV_16SC2) # , rmap[0][0], rmap[0][1]);\n",
        "right_map1, right_map2 = cv2.initUndistortRectifyMap(\n",
        "    cameraMatrix=scalib_results.camera_matrix_right,\n",
        "    distCoeffs=scalib_results.dist_coeffs_right,\n",
        "    R=srect_results.R2,\n",
        "    newCameraMatrix=srect_results.P2, size=shapes, m1type=cv2.CV_16SC2\n",
        ")"
      ],
      "metadata": {
        "id": "QVEUPf9r33Xm"
      },
      "id": "QVEUPf9r33Xm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_rimage = cv2.remap(\n",
        "    stereo_calib_data.image_data_left.iloc[0],\n",
        "    left_map1, left_map2, cv2.INTER_LINEAR)\n",
        "right_rimage = cv2.remap(\n",
        "    stereo_calib_data.image_data_right.iloc[0],\n",
        "    right_map1, right_map2, cv2.INTER_LINEAR)"
      ],
      "metadata": {
        "id": "ui2NWq7250hO"
      },
      "id": "ui2NWq7250hO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depth estimation with SIFT algorithm"
      ],
      "metadata": {
        "id": "gCQdfvVd9zEk"
      },
      "id": "gCQdfvVd9zEk"
    },
    {
      "cell_type": "code",
      "source": [
        "kp1, des1 = calculate_sift_descriptors(image=left_rimage)\n",
        "kp2, des2 = calculate_sift_descriptors(image=right_rimage)\n",
        "\n",
        "left_pts, right_pts = calculate_match_points(\n",
        "    kp1=kp1, des1=des1,\n",
        "    kp2=kp2, des2=des2)\n",
        "draw_matched_points(\n",
        "    left_image=left_rimage,\n",
        "    right_image=right_rimage,\n",
        "    left_points=left_pts,\n",
        "    right_points=right_pts\n",
        ")"
      ],
      "metadata": {
        "id": "xDduOBnzVk-f"
      },
      "id": "xDduOBnzVk-f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fm, mask = calculate_fundamental_matrix(\n",
        "    p1=left_pts, p2=right_pts\n",
        ")\n",
        "left_pts_filtered = numpy.array(left_pts)[mask.ravel()==1]\n",
        "right_pts_filtered = numpy.array(right_pts)[mask.ravel()==1]\n",
        "\n",
        "draw_matched_points(\n",
        "    left_image=left_rimage,\n",
        "    right_image=right_rimage,\n",
        "    left_points=left_pts_filtered,\n",
        "    right_points=right_pts_filtered\n",
        ")\n",
        "print(len(left_pts_filtered))"
      ],
      "metadata": {
        "id": "7j0xE8IaHbgk"
      },
      "id": "7j0xE8IaHbgk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depth estimation with ORB descriptors"
      ],
      "metadata": {
        "id": "wsRRdQnqQzAg"
      },
      "id": "wsRRdQnqQzAg"
    },
    {
      "cell_type": "code",
      "source": [
        "kp1, des1 = calculate_orb_descriptors(image=left_rimage)\n",
        "kp2, des2 = calculate_orb_descriptors(image=right_rimage)\n",
        "\n",
        "left_pts, right_pts = calculate_match_points(\n",
        "    kp1=kp1, des1=des1.astype(numpy.float32),\n",
        "    kp2=kp2, des2=des2.astype(numpy.float32))\n",
        "draw_matched_points(\n",
        "    left_image=left_rimage,\n",
        "    right_image=right_rimage,\n",
        "    left_points=left_pts,\n",
        "    right_points=right_pts\n",
        ")"
      ],
      "metadata": {
        "id": "pQG44y7mQs9M"
      },
      "id": "pQG44y7mQs9M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depth estimation with manual points\n",
        "\n",
        "Below few points were manualy matched between left/right image to calculate disparity and estimate depth by Q matrix that was calculated for calibrated stereo pair."
      ],
      "metadata": {
        "id": "ejz2dE7nCmI0"
      },
      "id": "ejz2dE7nCmI0"
    },
    {
      "cell_type": "code",
      "source": [
        "pts1 = numpy.array([[385.0, 624.0, 533.0, 535.0, 261.0, 416.0],\n",
        "                    [28.0, 38.0, 211.0, 233.0, 0.0, 245.0]])\n",
        "pts2 = numpy.array([[93.0, 304.0, 146.0, 120.0, 257.0, 1054.0-639.0],\n",
        "                    [28.0, 38.0, 211.0, 233.0, 0.0, 242.0]])\n",
        "disp = pts1[0,:] - pts2[0, :]\n",
        "pts1, pts2, disp"
      ],
      "metadata": {
        "id": "8yo58YjFIz7n"
      },
      "id": "8yo58YjFIz7n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=left_rimage,\n",
        "    right_image=right_rimage,\n",
        "    left_points=pts1.swapaxes(0, 1),\n",
        "    right_points=pts2.swapaxes(0, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "0N9XSYwz9G1R"
      },
      "id": "0N9XSYwz9G1R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below 1 value was added to each point for compartability with scaling representation."
      ],
      "metadata": {
        "id": "eL_E7kxcE3HV"
      },
      "id": "eL_E7kxcE3HV"
    },
    {
      "cell_type": "code",
      "source": [
        "pts = numpy.concatenate((pts1, disp.reshape(1, -1), numpy.ones((1, pts1.shape[1]))))\n",
        "pts, disp"
      ],
      "metadata": {
        "id": "933j9zZf0wm3"
      },
      "id": "933j9zZf0wm3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculates 3D from 2D in scaled dimension"
      ],
      "metadata": {
        "id": "8ht8C-fcFHIF"
      },
      "id": "8ht8C-fcFHIF"
    },
    {
      "cell_type": "code",
      "source": [
        "points4d = cv2.triangulatePoints(projMatr1=srect_results.P1,\n",
        "                                 projMatr2=srect_results.P2,\n",
        "                                 projPoints1=pts1,\n",
        "                                 projPoints2=pts2)\n",
        "points4d"
      ],
      "metadata": {
        "id": "ukL9nHgi0WwA"
      },
      "id": "ukL9nHgi0WwA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removes scaling"
      ],
      "metadata": {
        "id": "000R894YFYf9"
      },
      "id": "000R894YFYf9"
    },
    {
      "cell_type": "code",
      "source": [
        "points = (points4d[:-1, :]/points4d[-1, :]).swapaxes(0, 1)\n",
        "points"
      ],
      "metadata": {
        "id": "UUrZcXZzbyw9"
      },
      "id": "UUrZcXZzbyw9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "actual_points = numpy.array(\n",
        "    [[0.0, 0.0, 0.0], [6.0, 0.0, 0.0], [6.0, 8.0, 0.0]]\n",
        ")"
      ],
      "metadata": {
        "id": "4SVLrke6IMUa"
      },
      "id": "4SVLrke6IMUa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checks hypotesis for three points on checkbord (6x8x10 triangle + single 90 and two 45 angles between its sides)"
      ],
      "metadata": {
        "id": "vR6MF4JqFfFg"
      },
      "id": "vR6MF4JqFfFg"
    },
    {
      "cell_type": "code",
      "source": [
        "ab_vector = points[1] - points[0]\n",
        "ab_norm = numpy.linalg.norm(ab_vector, ord=2)\n",
        "bc_vector = points[2] - points[1]\n",
        "bc_norm = numpy.linalg.norm(bc_vector, ord=2)\n",
        "ac_vector = points[2] - points[0]\n",
        "ac_norm = numpy.linalg.norm(ac_vector, ord=2)\n",
        "\n",
        "actual_ab_vector = actual_points[1] - actual_points[0]\n",
        "actual_ab_norm = numpy.linalg.norm(actual_ab_vector, ord=2)\n",
        "actual_bc_vector = actual_points[2] - actual_points[1]\n",
        "actual_bc_norm = numpy.linalg.norm(actual_bc_vector, ord=2)\n",
        "actual_ac_vector = actual_points[2] - actual_points[0]\n",
        "actual_ac_norm = numpy.linalg.norm(actual_ac_vector, ord=2)"
      ],
      "metadata": {
        "id": "qJM9wIP9pth1"
      },
      "id": "qJM9wIP9pth1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"estimated\": (ab_norm, bc_norm, ac_norm),\n",
        "    \"actual\": (actual_ab_norm, actual_bc_norm, actual_ac_norm)\n",
        "}"
      ],
      "metadata": {
        "id": "ScgLVu8xrZy4"
      },
      "id": "ScgLVu8xrZy4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Angles are calculated from vectors scalar value:\n",
        "\n",
        "$\\overrightarrow a \\cdot \\overrightarrow b = |a| |b| cos(\\angle ab)$"
      ],
      "metadata": {
        "id": "3OFhb5R1GJwp"
      },
      "id": "3OFhb5R1GJwp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\angle AB,BC$"
      ],
      "metadata": {
        "id": "uUpGH3EFHD_s"
      },
      "id": "uUpGH3EFHD_s"
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"estimated\": calculate_angle(ab_vector, bc_vector),\n",
        "    \"actual\": calculate_angle(actual_ab_vector, actual_bc_vector)\n",
        "}"
      ],
      "metadata": {
        "id": "-Kbh1E_z4i8m"
      },
      "id": "-Kbh1E_z4i8m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\angle AB,AC$"
      ],
      "metadata": {
        "id": "_mguZE-2HLMX"
      },
      "id": "_mguZE-2HLMX"
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"estimated\": calculate_angle(ab_vector, ac_vector),\n",
        "    \"actual\": calculate_angle(actual_ab_vector, actual_ac_vector)\n",
        "}"
      ],
      "metadata": {
        "id": "uIIic5dgHCXB"
      },
      "id": "uIIic5dgHCXB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\angle AC,BC$"
      ],
      "metadata": {
        "id": "bP-wBwmrHTpR"
      },
      "id": "bP-wBwmrHTpR"
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "    \"estimated\": calculate_angle(ac_vector, bc_vector),\n",
        "    \"actual\": calculate_angle(actual_ac_vector, actual_bc_vector)\n",
        "}"
      ],
      "metadata": {
        "id": "junLJNb8Hajz"
      },
      "id": "junLJNb8Hajz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Depth estimation with out of the box algorithm (block match)"
      ],
      "metadata": {
        "id": "If2cveprtKbr"
      },
      "id": "If2cveprtKbr"
    },
    {
      "cell_type": "code",
      "source": [
        "stereo = cv2.StereoBM.create(numDisparities=256, blockSize=5)\n",
        "left_rgray = cv2.cvtColor(left_rimage, cv2.COLOR_BGR2GRAY)\n",
        "right_rgray = cv2.cvtColor(right_rimage, cv2.COLOR_BGR2GRAY)\n",
        "disparity = stereo.compute(left_rgray, right_rgray)\n",
        "plte.imshow(disparity).show()"
      ],
      "metadata": {
        "id": "Ok5XBKbm62dg"
      },
      "id": "Ok5XBKbm62dg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web camera experiments"
      ],
      "metadata": {
        "id": "3fI4ImiCkCCy"
      },
      "id": "3fI4ImiCkCCy"
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O real-samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-real-test/position.csv"
      ],
      "metadata": {
        "id": "_Vm_vOFnvjmN"
      },
      "id": "_Vm_vOFnvjmN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-real-test/{}\"\n",
        "dataframe = pandas.read_csv(\"real-samples.csv\", sep=',')\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            load_single_image,\n",
        "            url_template=base_url),\n",
        "        axis=1)\n",
        ")\n",
        "plte.imshow(draw_image_sequence(dataframe.image_data.iloc[1], dataframe.image_data.iloc[0]))"
      ],
      "metadata": {
        "id": "WmkIorldgyqo"
      },
      "id": "WmkIorldgyqo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_image = dataframe[dataframe[\"type\"] == \"l\"][\"image_data\"].iloc[0]\n",
        "right_image = dataframe[dataframe[\"type\"] == \"r\"][\"image_data\"].iloc[0]"
      ],
      "metadata": {
        "id": "6nS7kpmKsWvM"
      },
      "id": "6nS7kpmKsWvM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kp1, des1 = calculate_sift_descriptors(image=left_image)\n",
        "kp2, des2 = calculate_sift_descriptors(image=right_image)\n",
        "\n",
        "left_pts, right_pts = calculate_match_points(\n",
        "    kp1=kp1, des1=des1.astype(numpy.float32),\n",
        "    kp2=kp2, des2=des2.astype(numpy.float32))\n",
        "draw_matched_points(\n",
        "    left_image=left_image,\n",
        "    right_image=right_image,\n",
        "    left_points=left_pts,\n",
        "    right_points=right_pts\n",
        ")"
      ],
      "metadata": {
        "id": "gf_a-kFrsL4B"
      },
      "id": "gf_a-kFrsL4B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fm, mask = calculate_fundamental_matrix(\n",
        "    p1=left_pts, p2=right_pts\n",
        ")\n",
        "left_pts_filtered = numpy.array(left_pts)[mask.ravel()==1]\n",
        "right_pts_filtered = numpy.array(right_pts)[mask.ravel()==1]"
      ],
      "metadata": {
        "id": "zFvi69YUAS3C"
      },
      "id": "zFvi69YUAS3C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=left_image,\n",
        "    right_image=right_image,\n",
        "    left_points=left_pts_filtered,\n",
        "    right_points=right_pts_filtered\n",
        ")"
      ],
      "metadata": {
        "id": "_VHhmbv2Aj3b"
      },
      "id": "_VHhmbv2Aj3b",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}