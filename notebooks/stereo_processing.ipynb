{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNzMEcRmD7BBJHNdLtrKJI0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHV8cwuwHWvH"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/ant-nik/semares/raw/master/data/stereo-camera-cyl/calibrated/triangulate_P1.npy\n",
        "!wget https://github.com/ant-nik/semares/raw/master/data/stereo-camera-cyl/calibrated/triangulate_P2.npy\n",
        "!wget https://github.com/ant-nik/semares/raw/master/data/stereo-camera-cyl/calibrated/left_map1.npy\n",
        "!wget https://github.com/ant-nik/semares/raw/master/data/stereo-camera-cyl/calibrated/left_map2.npy\n",
        "!wget https://github.com/ant-nik/semares/raw/master/data/stereo-camera-cyl/calibrated/right_map1.npy\n",
        "!wget https://github.com/ant-nik/semares/raw/master/data/stereo-camera-cyl/calibrated/right_map2.npy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "import numpy\n",
        "import logging\n",
        "import functools\n",
        "import requests\n",
        "import cv2\n",
        "import io\n",
        "import plotly.express as plte\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "def load_image(payload: any) -> any:\n",
        "    np_image = numpy.frombuffer(payload, numpy.uint8)\n",
        "    img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def load_single_image(item: pandas.Series, url_template: str) -> numpy.ndarray:\n",
        "    item_file = item[\"image\"].lstrip(\" \")\n",
        "    url = url_template.format(item_file)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        logger.error(\"Can't read image %s from url %s\", item_file, url)\n",
        "    return pandas.Series([load_image(response.content), url],\n",
        "                         index=[\"image_data\", \"url\"])\n",
        "\n",
        "    import numpy as np\n",
        "import cv2 as cv\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def calculate_sift_descriptors(image: any) -> tuple[any, any]:\n",
        "    sift = cv2.SIFT_create()\n",
        "    # find the keypoints and descriptors with SIFT\n",
        "    return sift.detectAndCompute(image, None)\n",
        "\n",
        "\n",
        "def calculate_orb_descriptors(image: numpy.ndarray) -> tuple[any, any]:\n",
        "    orb = cv.ORB_create()\n",
        "    # find the keypoints with ORB\n",
        "    kp = orb.detect(image, None)\n",
        "    # compute the descriptors with ORB\n",
        "    kp, des = orb.compute(image, kp)\n",
        "\n",
        "    return kp, des\n",
        "\n",
        "\n",
        "def calculate_match_points(\n",
        "        kp1: numpy.ndarray,\n",
        "        des1: numpy.ndarray,\n",
        "        kp2: numpy.ndarray,\n",
        "        des2: numpy.ndarray) -> tuple[list, list]:\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    pts1 = []\n",
        "    pts2 = []\n",
        "\n",
        "    # ratio test as per Lowe's paper\n",
        "    for i,(m,n) in enumerate(matches):\n",
        "        if m.distance < 0.8*n.distance:\n",
        "            pts2.append(kp2[m.trainIdx].pt)\n",
        "            pts1.append(kp1[m.queryIdx].pt)\n",
        "\n",
        "    return pts1, pts2\n",
        "\n",
        "\n",
        "def calculate_fundamental_matrix(\n",
        "    p1: numpy.ndarray, p2: numpy.ndarray\n",
        ") -> tuple[numpy.ndarray, numpy.ndarray]:\n",
        "    p1 = numpy.int32(p1)\n",
        "    p2 = numpy.int32(p2)\n",
        "    return cv2.findFundamentalMat(p1, p2, cv2.FM_LMEDS)\n",
        "\n",
        "\n",
        "def draw_matched_points(\n",
        "    left_image: numpy.ndarray,\n",
        "    right_image: numpy.ndarray,\n",
        "    left_points: numpy.ndarray,\n",
        "    right_points: numpy.ndarray\n",
        ") -> None:\n",
        "    canvas_shape = list(left_image.shape)\n",
        "    canvas_shape[1] = canvas_shape[1]*2\n",
        "    canvas = numpy.zeros(canvas_shape)\n",
        "    canvas[:, 0:left_image.shape[1], :] = left_image\n",
        "    canvas[:, left_image.shape[1]:, :] = right_image\n",
        "    for p_left, p_right in zip(left_points, right_points):\n",
        "        color = tuple(numpy.random.randint(0, 255, 3).tolist())\n",
        "        left_point = tuple(map(int, p_left))\n",
        "        canvas = cv2.circle(canvas, left_point, 5, color,-1)\n",
        "        p_right_shifted = list(p_right)\n",
        "        p_right_shifted[0] = p_right_shifted[0] + left_image.shape[1]\n",
        "        right_point = tuple(map(int, p_right_shifted))\n",
        "        canvas = cv2.circle(canvas, right_point, 5, color,-1)\n",
        "        canvas = cv2.line(canvas, left_point, right_point, (0, 255, 0), 1)\n",
        "    fig = plte.imshow(canvas)\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def draw_image_sequence(*args, axis=1) -> numpy.ndarray:\n",
        "    if len(args) == 0:\n",
        "        return numpy.ndarray()\n",
        "\n",
        "    w = args[0].shape[1]\n",
        "    h = args[0].shape[0]\n",
        "    canvas_shape = list(args[0].shape)\n",
        "    canvas_shape[axis] = canvas_shape[axis]*len(args)\n",
        "    canvas = numpy.zeros(canvas_shape)\n",
        "    for i in range(0, len(args)):\n",
        "        if axis == 1:\n",
        "            canvas[:, i*w:(i + 1)*w, :] = args[i]\n",
        "        else:\n",
        "            canvas[i*w:(i + 1)*w, :, :] = args[i]\n",
        "\n",
        "    return canvas"
      ],
      "metadata": {
        "id": "aWc_OinlKCrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "\n",
        "\n",
        "P1 = numpy.load(\"triangulate_P1.npy\")\n",
        "P2 = numpy.load(\"triangulate_P2.npy\")\n",
        "left_map1 = numpy.load(\"left_map1.npy\")\n",
        "left_map2 = numpy.load(\"left_map2.npy\")\n",
        "right_map1 = numpy.load(\"right_map1.npy\")\n",
        "right_map2 = numpy.load(\"right_map2.npy\")"
      ],
      "metadata": {
        "id": "8SlG0TN7HfEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/position.csv"
      ],
      "metadata": {
        "id": "p87mVP84J26n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/{}\"\n",
        "\n",
        "dataframe = pandas.read_csv(\"samples.csv\", sep=',')\n",
        "dataframe = dataframe.join(\n",
        "    dataframe.apply(\n",
        "        functools.partial(\n",
        "            load_single_image,\n",
        "            url_template=base_url),\n",
        "        axis=1)\n",
        ")"
      ],
      "metadata": {
        "id": "QJR0NuXBJ6dQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_image_1 = dataframe[dataframe[\"image\"] == \"image36_l.jpg\"][\"image_data\"].iloc[0]\n",
        "right_image_1 = dataframe[dataframe[\"image\"] == \"image36_r.jpg\"][\"image_data\"].iloc[0]"
      ],
      "metadata": {
        "id": "Hx3P9-mRHkue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plte.imshow(draw_image_sequence(left_image_1, right_image_1))"
      ],
      "metadata": {
        "id": "6q1zQh4pM-2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_map1.shape"
      ],
      "metadata": {
        "id": "ArZVHJp23dAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "left_rimage_2 = cv2.remap(\n",
        "    left_image_1,\n",
        "    left_map1, left_map2, cv2.INTER_LINEAR)\n",
        "right_rimage_2 = cv2.remap(\n",
        "    right_image_1,\n",
        "    right_map1, right_map2, cv2.INTER_LINEAR)"
      ],
      "metadata": {
        "id": "hUujxcVqM91q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kp1, des1 = calculate_sift_descriptors(image=left_rimage_2)\n",
        "kp2, des2 = calculate_sift_descriptors(image=right_rimage_2)\n",
        "\n",
        "left_pts, right_pts = calculate_match_points(\n",
        "    kp1=kp1, des1=des1,\n",
        "    kp2=kp2, des2=des2)"
      ],
      "metadata": {
        "id": "d1I4OJTrLBar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=left_rimage_2,\n",
        "    right_image=right_rimage_2,\n",
        "    left_points=left_pts,\n",
        "    right_points=right_pts\n",
        ")"
      ],
      "metadata": {
        "id": "MIMSRjTtBVgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Fm, mask = calculate_fundamental_matrix(\n",
        "    p1=left_pts, p2=right_pts\n",
        ")\n",
        "left_pts_filtered = numpy.array(left_pts)[mask.ravel()==1]\n",
        "right_pts_filtered = numpy.array(right_pts)[mask.ravel()==1]"
      ],
      "metadata": {
        "id": "-3GPhHYgBk9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_matched_points(\n",
        "    left_image=left_rimage_2,\n",
        "    right_image=right_rimage_2,\n",
        "    left_points=left_pts_filtered,\n",
        "    right_points=right_pts_filtered\n",
        ")"
      ],
      "metadata": {
        "id": "3HeNJvVZB76h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N1dYVqpbCAO2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}