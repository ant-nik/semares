{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0",
      "metadata": {
        "id": "8339f92b-cf1d-4bab-a80b-cf467cbe9ba0"
      },
      "source": [
        "# Camera calibration"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6468cf32-7430-49eb-8576-1f798ef0c846",
      "metadata": {
        "id": "6468cf32-7430-49eb-8576-1f798ef0c846"
      },
      "source": [
        "Notebook is based on OpenCV tutorial (https://docs.opencv.org/4.x/dc/dbb/tutorial_py_calibration.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0",
      "metadata": {
        "id": "5a3183f6-5757-4586-b0bc-0c2bf0e51bd0"
      },
      "outputs": [],
      "source": [
        "!wget -O samples.csv https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/position.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import logging\n",
        "import io\n",
        "import numpy\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "# termination criteria\n",
        "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
        "\n",
        "\n",
        "def load_image(payload: any) -> any:\n",
        "    np_image = numpy.frombuffer(payload, numpy.uint8)\n",
        "    img = cv2.imdecode(np_image, cv2.IMREAD_COLOR)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def get_chess_corners_from_image(\n",
        "        image: any, corners_x: int, corners_y: int) -> tuple[any, any]:\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Find the chess board corners\n",
        "    ret, corners = cv2.findChessboardCorners(gray, (corners_x, corners_y), None)\n",
        "\n",
        "    # If found, add object points, image points (after refining them)\n",
        "    if ret != True:\n",
        "        logger.error(\"Error, grid (%d, %d) is not found in image\",\n",
        "                     corners_x, corners_y)\n",
        "        return None, gray\n",
        "\n",
        "    corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1,-1), criteria)\n",
        "    result_image = cv2.drawChessboardCorners(image, (7,7), corners, True)\n",
        "    return corners2, result_image\n",
        "\n",
        "\n",
        "def undistort_image(image: numpy.ndarray, mtx: numpy.ndarray,\n",
        "                    dist: numpy.ndarray, new_mtx: numpy.ndarray,\n",
        "                    canvas_w: int, canvas_h: int) -> numpy.ndarray:\n",
        "    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, new_mtx,\n",
        "                                             (canvas_w, canvas_h), 5)\n",
        "    return cv2.remap(image, mapx, mapy, cv2.INTER_LINEAR)\n"
      ],
      "metadata": {
        "id": "8cpIb1CoYF0Q"
      },
      "id": "8cpIb1CoYF0Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as plte\n",
        "import requests\n",
        "import logging\n",
        "import pandas\n",
        "import dataclasses\n",
        "\n",
        "\n",
        "@dataclasses.dataclass\n",
        "class Grid:\n",
        "    name: str\n",
        "    url: str\n",
        "    corners_x: int\n",
        "    corners_y: int\n",
        "    corners: any\n",
        "    image: any\n",
        "    obj_points: any = None\n",
        "    rvec: numpy.ndarray = None\n",
        "    tvec: numpy.ndarray = None\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "base_url = \"https://raw.githubusercontent.com/ant-nik/semares/master/data/stereo-camera-cyl/{}\"\n",
        "\n",
        "# set to None if all items are aceptable\n",
        "acepted_items = [\n",
        "    \"image0_r.jpg\",\n",
        "    \"image0_l.jpg\",\n",
        "    \"image61_r.jpg\",\n",
        "    \"image61_l.jpg\",\n",
        "    \"image68_r.jpg\",\n",
        "    \"image68_l.jpg\",\n",
        "    # \"image75_r.jpg\",\n",
        "    \"image75_l.jpg\",\n",
        "    \"image83_r.jpg\",\n",
        "    \"image83_l.jpg\",\n",
        "    #\"image84_r.jpg\",\n",
        "    #\"image84_l.jpg\",\n",
        "    # \"image89_r.jpg\",\n",
        "    #\"image89_l.jpg\",\n",
        "    #\"image91_r.jpg\",\n",
        "    #\"image91_l.jpg\"\n",
        "]\n",
        "\n",
        "sample_dataframe = pandas.read_csv('samples.csv', sep=',')\n",
        "samples: list[Grid] = []\n",
        "orig_files = []\n",
        "for index, item in sample_dataframe.iterrows():\n",
        "    item_file = item[\"image\"].lstrip(\" \")\n",
        "    url = base_url.format(item_file)\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        logger.error(\"Can't read image %s from url %s\", item_file, url)\n",
        "    # Draw and display the corners\n",
        "    orig_image = load_image(response.content)\n",
        "    orig_files.append(numpy.array(orig_image))\n",
        "    if acepted_items is not None and not item_file in acepted_items:\n",
        "        logger.warning(\"Item %s is skipped because it is not in accepted list\",\n",
        "                       item_file)\n",
        "        continue\n",
        "    corners, image = get_chess_corners_from_image(\n",
        "        image=orig_image,\n",
        "        corners_x=item[\"corners_x\"],\n",
        "        corners_y=item[\"corners_y\"]\n",
        "    )\n",
        "    if corners is None:\n",
        "        logger.error(\"Can't find %d, %d conrenrs in %s\",\n",
        "                     item[\"corners_x\"], item[\"corners_y\"], item_file)\n",
        "    grid = Grid(\n",
        "        name=item_file,\n",
        "        url=url,\n",
        "        corners_x=item[\"corners_x\"],\n",
        "        corners_y=item[\"corners_y\"],\n",
        "        corners=corners,\n",
        "        image=image\n",
        "    )\n",
        "    samples.append(grid)\n",
        "\n",
        "sample_dataframe = sample_dataframe.assign(image_data=orig_files)"
      ],
      "metadata": {
        "id": "A-bXJHcUVF8R"
      },
      "id": "A-bXJHcUVF8R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "obj_points = []\n",
        "img_points = []\n",
        "objects = []\n",
        "shapes = None\n",
        "for sample in samples:\n",
        "    if sample.corners is None:\n",
        "        continue\n",
        "\n",
        "    objp = numpy.zeros((sample.corners_x*sample.corners_y,3), numpy.float32)\n",
        "    objp[:,:2] = numpy.mgrid[0:sample.corners_x,0:sample.corners_y].T.reshape(\n",
        "        -1, 2)\n",
        "    objp = objp\n",
        "    img_shape = (sample.image.shape[1], sample.image.shape[0])\n",
        "    if not shapes is None and shapes != img_shape:\n",
        "        logger.error(\n",
        "            \"Image %s has specific shape %s that is not equals to previously shapes: %s\",\n",
        "            sample.name, str(img_shape), str(shapes)\n",
        "            )\n",
        "        continue\n",
        "    if shapes is None:\n",
        "        shapes = img_shape\n",
        "    sample.obj_points = objp\n",
        "    obj_points.append(objp)\n",
        "    img_points.append(sample.corners)\n",
        "    objects.append(sample)\n",
        "\n",
        "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
        "    obj_points, img_points, shapes, None, None)\n",
        "for i in range(0, len(objects)):\n",
        "    objects[i].rvec = rvecs[i]\n",
        "    objects[i].tvec = tvecs[i]\n",
        "ret, mtx, dist"
      ],
      "metadata": {
        "id": "1X1j9pP1Xnt3"
      },
      "id": "1X1j9pP1Xnt3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = shapes[0]\n",
        "h = shapes[1]\n",
        "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
        "(roi, newcameramtx)"
      ],
      "metadata": {
        "id": "2Mj2W9YiIuDX"
      },
      "id": "2Mj2W9YiIuDX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "names = []\n",
        "error_threshold = 0.15\n",
        "axis = numpy.float32([[3,0,0], [0,3,0], [0,0,-3]]).reshape(-1,3)\n",
        "color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
        "undistorted_images = []\n",
        "\n",
        "for sample in samples:\n",
        "    if sample.corners is None:\n",
        "        fig = plte.imshow(sample.image, title=sample.name)\n",
        "        fig.show()\n",
        "        logger.warning(\"Image %s has no detected chessboard corners, skipping...\",\n",
        "                       sample.name)\n",
        "        continue\n",
        "    pre_dst = undistort_image(\n",
        "        image=sample.image,\n",
        "        mtx=mtx, dist=dist, new_mtx=newcameramtx,\n",
        "        canvas_w=shapes[0], canvas_h=shapes[1])\n",
        "    # crop the image\n",
        "    x, y, w, h = roi\n",
        "    dst = pre_dst # [y:y + h, x:x + w]\n",
        "    imgpoints, _ = cv2.projectPoints(\n",
        "        sample.obj_points, sample.rvec, sample.tvec, mtx, dist)\n",
        "    error = cv2.norm(sample.corners, imgpoints, cv2.NORM_L2)/len(imgpoints)\n",
        "    if error < error_threshold:\n",
        "        names.append(sample.name)\n",
        "    # axis2d, jac = cv2.projectPoints(axis, sample.rvec, sample.tvec, mtx, dist)\n",
        "    #origin = tuple([int(v) for v in sample.corners[0].ravel()])\n",
        "    #for i in range(0, 3):\n",
        "    #    dst = cv2.line(dst, origin, tuple(\n",
        "    #        [int(v) for v in axis2d[i].ravel()]), color[i], 5)\n",
        "    lwidth = 2\n",
        "    dst = cv2.line(dst, (x, y), (x + w, y), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y), (x + w, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x + w, y + h), (x, y + h), (0, 255, 0), lwidth)\n",
        "    dst = cv2.line(dst, (x, y + h), (x, y), (0, 255, 0), lwidth)\n",
        "    fig = plte.imshow(\n",
        "        dst,\n",
        "        title=f\"image {sample.name},crop[x,y,w,h]={roi},error={error}\")\n",
        "    fig.show()\n"
      ],
      "metadata": {
        "id": "NZHfpvEaDT8x"
      },
      "id": "NZHfpvEaDT8x",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Epipolar lines"
      ],
      "metadata": {
        "id": "vaAa3206Twko"
      },
      "id": "vaAa3206Twko"
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_descriptors(left_image: any, right_image: any\n",
        "                          ) -> tuple[any, any]:\n",
        "    sift = cv2.SIFT_create()\n",
        "    # find the keypoints and descriptors with SIFT\n",
        "    kp1, des1 = sift.detectAndCompute(left_image, None)\n",
        "    kp2, des2 = sift.detectAndCompute(right_image, None)\n",
        "\n",
        "    # FLANN parameters\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "    matches = flann.knnMatch(des1, des2, k=2)\n",
        "\n",
        "    pts1 = []\n",
        "    pts2 = []\n",
        "\n",
        "    # ratio test as per Lowe's paper\n",
        "    for i,(m,n) in enumerate(matches):\n",
        "        if m.distance < 0.8*n.distance:\n",
        "            pts2.append(kp2[m.trainIdx].pt)\n",
        "            pts1.append(kp1[m.queryIdx].pt)\n",
        "\n",
        "    return pts1, pts2"
      ],
      "metadata": {
        "id": "J-Jlda4KUv0E"
      },
      "id": "J-Jlda4KUv0E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y, w, h = roi\n",
        "first = sample_dataframe[sample_dataframe[\"no\"] == 0]\n",
        "first_left = undistort_image(\n",
        "    image=first[first[\"type\"] == \"l\"][\"image_data\"].iloc[0],\n",
        "    mtx=mtx, dist=dist, new_mtx=newcameramtx,\n",
        "    canvas_w=shapes[0], canvas_h=shapes[1])[y:y+h,x:x+w]\n",
        "first_right = undistort_image(\n",
        "    first[first[\"type\"] == \"r\"][\"image_data\"].iloc[0],\n",
        "    mtx=mtx, dist=dist, new_mtx=newcameramtx,\n",
        "    canvas_w=shapes[0], canvas_h=shapes[1])[y:y+h,x:x+w]\n",
        "left_pts, right_pts = calculate_descriptors(left_image=first_left,\n",
        "                                            right_image=first_right)"
      ],
      "metadata": {
        "id": "7L8DSJuuV-wI"
      },
      "id": "7L8DSJuuV-wI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "canvas_shape = list(first_left.shape)\n",
        "canvas_shape[1] = canvas_shape[1]*2\n",
        "canvas = numpy.zeros(canvas_shape)\n",
        "canvas[:,0:first_left.shape[1],:] = first_left\n",
        "canvas[:,first_left.shape[1]:,:] = first_right\n",
        "for p_left, p_right in zip(left_pts, right_pts):\n",
        "    color = tuple(numpy.random.randint(0, 255, 3).tolist())\n",
        "    left_point = tuple(map(int, p_left))\n",
        "    canvas = cv2.circle(canvas, left_point, 5, color,-1)\n",
        "    p_right_shifted = list(p_right)\n",
        "    p_right_shifted[0] = p_right_shifted[0] + first_left.shape[1]\n",
        "    right_point = tuple(map(int, p_right_shifted))\n",
        "    canvas = cv2.circle(canvas, right_point, 5, color,-1)\n",
        "    canvas = cv2.line(canvas, left_point, right_point, (0, 255, 0), 1)\n",
        "fig = plte.imshow(canvas)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "__5xQBT0gofE"
      },
      "id": "__5xQBT0gofE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install h5py omegaconf submitit"
      ],
      "metadata": {
        "id": "8Evw5Kuv5HP0"
      },
      "id": "8Evw5Kuv5HP0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ant-nik/MCC.git"
      ],
      "metadata": {
        "id": "sSxI6GjR-kYV"
      },
      "id": "sSxI6GjR-kYV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O MCC/checkpoint.pth https://dl.fbaipublicfiles.com/MCC/co3dv2_all_categories.pth"
      ],
      "metadata": {
        "id": "RS234iTG_K30"
      },
      "id": "RS234iTG_K30",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch\n",
        "pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
        "version_str=\"\".join([\n",
        "    f\"py3{sys.version_info.minor}_cu\",\n",
        "    torch.version.cuda.replace(\".\",\"\"),\n",
        "    f\"_pyt{pyt_version_str}\"\n",
        "])\n",
        "!pip install fvcore iopath\n",
        "!pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html"
      ],
      "metadata": {
        "id": "pivO0wVDAK88"
      },
      "id": "pivO0wVDAK88",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "pJmrvY_ZDI12"
      },
      "id": "pJmrvY_ZDI12",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd MCC && python demo.py --checkpoint checkpoint.pth --image demo/quest2.jpg # --point_cloud demo/quest23.obj --seg demo/quest24_seg.png"
      ],
      "metadata": {
        "id": "nb8t3DFV-yV8"
      },
      "id": "nb8t3DFV-yV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yzf_4jvn_uz_"
      },
      "id": "Yzf_4jvn_uz_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}